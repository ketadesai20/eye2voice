{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4d1dab",
   "metadata": {},
   "source": [
    "### Setup + Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fb642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import albumentations as A\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tqdm import tqdm  # for progress bar\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994471b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prevent my poor mac from overheating\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb632388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image metadata\n",
    "DATA_ROOT = Path(\"/Volumes/Crucial X10/210/data/columbia_gaze_dataset\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Regex for filename parsing\n",
    "pattern = re.compile(\n",
    "    r\"(?P<subject>\\d+)_\"\n",
    "    r\"(?P<distance>\\d+)m_\"\n",
    "    r\"(?P<head_pose>-?\\d+)P_\"\n",
    "    r\"(?P<gaze_v>-?\\d+)V_\"\n",
    "    r\"(?P<gaze_h>-?\\d+)H\\.jpg\"\n",
    ")\n",
    "\n",
    "for subject_dir in DATA_ROOT.iterdir():\n",
    "    if not subject_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for img_path in subject_dir.glob(\"*.jpg\"):\n",
    "        match = pattern.match(img_path.name)\n",
    "        if not match:\n",
    "            continue  # skip unexpected filenames\n",
    "\n",
    "        meta = match.groupdict()\n",
    "\n",
    "        rows.append({\n",
    "            \"path\": str(img_path),\n",
    "            \"filename\": img_path.name,\n",
    "            \"subject\": meta[\"subject\"],\n",
    "            \"distance_m\": int(meta[\"distance\"]),\n",
    "            \"head_pose_deg\": int(meta[\"head_pose\"]),\n",
    "            \"gaze_vertical_deg\": int(meta[\"gaze_v\"]),\n",
    "            \"gaze_horizontal_deg\": int(meta[\"gaze_h\"]),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1cf810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>subject</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>head_pose_deg</th>\n",
       "      <th>gaze_vertical_deg</th>\n",
       "      <th>gaze_horizontal_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Volumes/Crucial X10/210/data/columbia_gaze_da...</td>\n",
       "      <td>0050_2m_-30P_0V_-10H.jpg</td>\n",
       "      <td>0050</td>\n",
       "      <td>2</td>\n",
       "      <td>-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Volumes/Crucial X10/210/data/columbia_gaze_da...</td>\n",
       "      <td>0050_2m_30P_-10V_5H.jpg</td>\n",
       "      <td>0050</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Volumes/Crucial X10/210/data/columbia_gaze_da...</td>\n",
       "      <td>0050_2m_30P_-10V_-5H.jpg</td>\n",
       "      <td>0050</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-10</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Volumes/Crucial X10/210/data/columbia_gaze_da...</td>\n",
       "      <td>0050_2m_-15P_10V_-10H.jpg</td>\n",
       "      <td>0050</td>\n",
       "      <td>2</td>\n",
       "      <td>-15</td>\n",
       "      <td>10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Volumes/Crucial X10/210/data/columbia_gaze_da...</td>\n",
       "      <td>0050_2m_-15P_0V_5H.jpg</td>\n",
       "      <td>0050</td>\n",
       "      <td>2</td>\n",
       "      <td>-15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  /Volumes/Crucial X10/210/data/columbia_gaze_da...   \n",
       "1  /Volumes/Crucial X10/210/data/columbia_gaze_da...   \n",
       "2  /Volumes/Crucial X10/210/data/columbia_gaze_da...   \n",
       "3  /Volumes/Crucial X10/210/data/columbia_gaze_da...   \n",
       "4  /Volumes/Crucial X10/210/data/columbia_gaze_da...   \n",
       "\n",
       "                    filename subject  distance_m  head_pose_deg  \\\n",
       "0   0050_2m_-30P_0V_-10H.jpg    0050           2            -30   \n",
       "1    0050_2m_30P_-10V_5H.jpg    0050           2             30   \n",
       "2   0050_2m_30P_-10V_-5H.jpg    0050           2             30   \n",
       "3  0050_2m_-15P_10V_-10H.jpg    0050           2            -15   \n",
       "4     0050_2m_-15P_0V_5H.jpg    0050           2            -15   \n",
       "\n",
       "   gaze_vertical_deg  gaze_horizontal_deg  \n",
       "0                  0                  -10  \n",
       "1                -10                    5  \n",
       "2                -10                   -5  \n",
       "3                 10                  -10  \n",
       "4                  0                    5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5457d",
   "metadata": {},
   "source": [
    "### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525d462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels based on degrees\n",
    "def create_labels(row):\n",
    "    '''\n",
    "    converts per-image gaze metadata into an intent-level\n",
    "    classification\n",
    "    '''\n",
    "    h = row[\"gaze_horizontal_deg\"]\n",
    "    v = row[\"gaze_vertical_deg\"]\n",
    "\n",
    "    # straight\n",
    "    if v==0 and h==0: \n",
    "        return \"straight\"\n",
    "    \n",
    "    # horizontal dominates\n",
    "    if abs(h) > abs(v):\n",
    "        return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "    # vertical dominates\n",
    "    if abs(v) > abs(h):\n",
    "        return \"down\" if v < 0 else \"up\"\n",
    "\n",
    "    # tie â†’ horizontal wins (gaze is steadier in horizontal axis)\n",
    "    return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "df[\"label\"] = df.apply(create_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628a423",
   "metadata": {},
   "source": [
    "### Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c4b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_ROOT = Path(\"/Volumes/Crucial X10/210/data/columbia_gaze_dataset\")\n",
    "OUTPUT_ROOT = Path(\"/Volumes/Crucial X10/210/data/columbia_gaze_augmented\")\n",
    "\n",
    "# will end up with dataset size = N original images x augmentations\n",
    "NUM_AUGMENTATIONS = 5 \n",
    "\n",
    "# distance varies wildly in the wild so create diff size pics\n",
    "TARGET_SIZES = [(224, 224), (192, 192), (256, 256)]\n",
    "\n",
    "# num of images to process at once; adjust based on needs\n",
    "# 75 is recommended for M1 mac with adequate disk space\n",
    "BATCH_SIZE = 75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09af3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/572hqr1x26j5sf69pfl_2fd80000gn/T/ipykernel_21431/3840305309.py:48: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
      "/var/folders/89/572hqr1x26j5sf69pfl_2fd80000gn/T/ipykernel_21431/3840305309.py:52: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=60, quality_upper=100, p=0.4),\n",
      "/var/folders/89/572hqr1x26j5sf69pfl_2fd80000gn/T/ipykernel_21431/3840305309.py:56: UserWarning: Argument(s) 'fog_coef_lower, fog_coef_upper' are not valid for transform RandomFog\n",
      "  A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=1.0),\n"
     ]
    }
   ],
   "source": [
    "augmentation = A.Compose([\n",
    "    # Geometric transformations - simulate different distances/angles\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.15,      # More head position variance\n",
    "        scale_limit=0.25,      # Simulate 1m to 3m+ distances\n",
    "        rotate_limit=20,       # More head tilt tolerance\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        p=0.8\n",
    "    ),\n",
    "    \n",
    "    # Perspective changes - simulate camera angles\n",
    "    A.Perspective(\n",
    "        scale=(0.05, 0.15),\n",
    "        p=0.5\n",
    "    ),\n",
    "    \n",
    "    # Lighting variations - crucial for real-world\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.3,\n",
    "            contrast_limit=0.3,\n",
    "            p=1.0\n",
    "        ),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=1.0),\n",
    "        A.CLAHE(clip_limit=4.0, p=1.0),  # Handles harsh lighting\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # Color temperature shifts\n",
    "    A.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1,\n",
    "        p=0.5\n",
    "    ),\n",
    "    \n",
    "    # Simulate poor lighting conditions\n",
    "    A.RandomShadow(\n",
    "        shadow_roi=(0, 0, 1, 1),\n",
    "        num_shadows_limit=(1,2),\n",
    "        p=0.3\n",
    "    ),\n",
    "    \n",
    "    # Camera quality degradation\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "        A.MotionBlur(blur_limit=7, p=1.0),  # Movement/tremors\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    # Compression artifacts (like video calls)\n",
    "    A.ImageCompression(quality_lower=60, quality_upper=100, p=0.4),\n",
    "    \n",
    "    # Occasional severe conditions\n",
    "    A.OneOf([\n",
    "        A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=1.0),\n",
    "        A.RandomRain(p=1.0),  # Window reflections, etc.\n",
    "    ], p=0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448221f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, label):\n",
    "    # Random resize to simulate different distances\n",
    "    target_size = TARGET_SIZES[np.random.randint(0, len(TARGET_SIZES))]  # â† Fixed\n",
    "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    transformed = augmentation(image=img_resized)\n",
    "    aug_img = transformed['image']\n",
    "    \n",
    "    # Final resize to consistent size for training\n",
    "    aug_img = cv2.resize(aug_img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return aug_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f357c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, output_root, num_augmentations):\n",
    "    \"\"\"Process a single batch of images.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in batch_df.iterrows():\n",
    "        # Load and resize image\n",
    "        img = cv2.imread(row['path'])\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load {row['path']}\")\n",
    "            continue\n",
    "            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create output directory for this subject\n",
    "        subject_dir = output_root / row['subject']\n",
    "        subject_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save resized original\n",
    "        stem = Path(row['filename']).stem\n",
    "        \n",
    "        # Process original (pick random size for variety)\n",
    "        target_size = TARGET_SIZES[np.random.randint(0, len(TARGET_SIZES))]\n",
    "        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "        img_final = cv2.resize(img_resized, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        orig_path = subject_dir / f\"{stem}.jpg\"\n",
    "        cv2.imwrite(str(orig_path), cv2.cvtColor(img_final, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Add original to results\n",
    "        results.append({\n",
    "            **row.to_dict(),\n",
    "            'augmented_path': str(orig_path),\n",
    "            'is_augmented': False,\n",
    "            'aug_id': 0\n",
    "        })\n",
    "        \n",
    "        # Generate augmentations\n",
    "        for aug_idx in range(1, num_augmentations + 1):\n",
    "            aug_img, aug_label = augment_image(img, row['label'])\n",
    "            \n",
    "            aug_path = subject_dir / f\"{stem}_aug{aug_idx}.jpg\"\n",
    "            cv2.imwrite(str(aug_path), cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            results.append({\n",
    "                **row.to_dict(),\n",
    "                'augmented_path': str(aug_path),\n",
    "                'label': aug_label,\n",
    "                'is_augmented': True,\n",
    "                'aug_id': aug_idx\n",
    "            })\n",
    "        \n",
    "        del img\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed83193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_dataset(df, output_root, batch_size, num_augmentations):\n",
    "    \"\"\"Process entire dataset in batches.\"\"\"\n",
    "    import gc\n",
    "    \n",
    "    output_root = Path(output_root)\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    total = len(df)\n",
    "    num_batches = (total + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nProcessing {total} images in {num_batches} batches of {batch_size}\")\n",
    "    print(f\"Creating {num_augmentations} augmentations per image\")\n",
    "    print(f\"Total output: {total * (num_augmentations + 1)} images\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Augmenting\"):\n",
    "        start = batch_idx * batch_size\n",
    "        end = min(start + batch_size, total)\n",
    "        batch_df = df.iloc[start:end]\n",
    "        \n",
    "        batch_results = process_batch(batch_df, output_root, num_augmentations)\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Force cleanup\n",
    "        gc.collect()\n",
    "    \n",
    "    return pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bba27",
   "metadata": {},
   "source": [
    "### Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5cd53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing with one batch (75 images)...\n",
      "\n",
      "âœ… Test complete!\n",
      "Processed 75 original images\n",
      "Created 450 total images (originals + augmentations)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "left        156\n",
      "right       138\n",
      "down         78\n",
      "up           54\n",
      "straight     24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Files saved to: /Volumes/Crucial X10/210/data/test_augmentation\n",
      "\n",
      "First few augmented files:\n",
      "                   filename label  is_augmented  aug_id\n",
      "0  0050_2m_-30P_0V_-10H.jpg  left         False       0\n",
      "1  0050_2m_-30P_0V_-10H.jpg  left          True       1\n",
      "2  0050_2m_-30P_0V_-10H.jpg  left          True       2\n",
      "3  0050_2m_-30P_0V_-10H.jpg  left          True       3\n",
      "4  0050_2m_-30P_0V_-10H.jpg  left          True       4\n",
      "5  0050_2m_-30P_0V_-10H.jpg  left          True       5\n",
      "6   0050_2m_30P_-10V_5H.jpg  down         False       0\n",
      "7   0050_2m_30P_-10V_5H.jpg  down          True       1\n",
      "8   0050_2m_30P_-10V_5H.jpg  down          True       2\n",
      "9   0050_2m_30P_-10V_5H.jpg  down          True       3\n"
     ]
    }
   ],
   "source": [
    "# Create a test batch (first 75 images)\n",
    "test_batch = df.iloc[:75]\n",
    "\n",
    "# Create a test output directory\n",
    "test_output = Path(\"/Volumes/Crucial X10/210/data/test_augmentation\")\n",
    "test_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run the single batch\n",
    "print(\"ðŸ§ª Testing with one batch (75 images)...\")\n",
    "test_results = process_batch(\n",
    "    batch_df=test_batch,\n",
    "    output_root=test_output,\n",
    "    num_augmentations=NUM_AUGMENTATIONS\n",
    ")\n",
    "\n",
    "# Convert to DataFrame to see results\n",
    "test_df = pd.DataFrame(test_results)\n",
    "\n",
    "print(f\"\\nâœ… Test complete!\")\n",
    "print(f\"Processed {len(test_batch)} original images\")\n",
    "print(f\"Created {len(test_df)} total images (originals + augmentations)\")\n",
    "print(f\"\\nLabel distribution:\\n{test_df['label'].value_counts()}\")\n",
    "print(f\"\\nFiles saved to: {test_output}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(f\"\\nFirst few augmented files:\")\n",
    "print(test_df[['filename', 'label', 'is_augmented', 'aug_id']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfcab6",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b99ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting augmentation process...\n",
      "\n",
      "Processing 5880 images in 79 batches of 75\n",
      "Creating 5 augmentations per image\n",
      "Total output: 35280 images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [45:52<00:00, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Augmentation complete!\n",
      "Total images: 35280\n",
      "Label distribution:\n",
      "label\n",
      "left        11760\n",
      "right       11760\n",
      "down         5040\n",
      "up           5040\n",
      "straight     1680\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ’¾ Saved metadata to: /Volumes/Crucial X10/210/data/columbia_gaze_augmented/augmented_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run augmentation\n",
    "print(\"ðŸš€ Starting augmentation process...\")\n",
    "augmented_df = process_full_dataset(\n",
    "    df=df,\n",
    "    output_root=OUTPUT_ROOT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_augmentations=NUM_AUGMENTATIONS\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Augmentation complete!\")\n",
    "print(f\"Total images: {len(augmented_df)}\")\n",
    "print(f\"Label distribution:\\n{augmented_df['label'].value_counts()}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = OUTPUT_ROOT / \"augmented_metadata.csv\"\n",
    "augmented_df.to_csv(metadata_path, index=False)\n",
    "print(f\"\\nðŸ’¾ Saved metadata to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad5dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

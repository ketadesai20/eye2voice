{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import albumentations as A\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tqdm import tqdm  # for progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994471b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent my poor mac from overheating\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb632388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image metadata\n",
    "DATA_ROOT = Path(\"~/Documents/00_210/data/columbia_gaze_dataset\").expanduser()\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Regex for filename parsing\n",
    "pattern = re.compile(\n",
    "    r\"(?P<subject>\\d+)_\"\n",
    "    r\"(?P<distance>\\d+)m_\"\n",
    "    r\"(?P<head_pose>-?\\d+)P_\"\n",
    "    r\"(?P<gaze_v>-?\\d+)V_\"\n",
    "    r\"(?P<gaze_h>-?\\d+)H\\.jpg\"\n",
    ")\n",
    "\n",
    "for subject_dir in DATA_ROOT.iterdir():\n",
    "    if not subject_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for img_path in subject_dir.glob(\"*.jpg\"):\n",
    "        match = pattern.match(img_path.name)\n",
    "        if not match:\n",
    "            continue  # skip unexpected filenames\n",
    "\n",
    "        meta = match.groupdict()\n",
    "\n",
    "        rows.append({\n",
    "            \"path\": str(img_path),\n",
    "            \"filename\": img_path.name,\n",
    "            \"subject\": meta[\"subject\"],\n",
    "            \"distance_m\": int(meta[\"distance\"]),\n",
    "            \"head_pose_deg\": int(meta[\"head_pose\"]),\n",
    "            \"gaze_vertical_deg\": int(meta[\"gaze_v\"]),\n",
    "            \"gaze_horizontal_deg\": int(meta[\"gaze_h\"]),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525d462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels based on degrees\n",
    "def create_labels(row):\n",
    "    '''\n",
    "    converts per-image gaze metadata into an intent-level\n",
    "    classification\n",
    "    '''\n",
    "    h = row[\"gaze_horizontal_deg\"]\n",
    "    v = row[\"gaze_vertical_deg\"]\n",
    "\n",
    "    # straight\n",
    "    if v==0 and h==0: \n",
    "        return \"straight\"\n",
    "    \n",
    "    # horizontal dominates\n",
    "    if abs(h) > abs(v):\n",
    "        return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "    # vertical dominates\n",
    "    if abs(v) > abs(h):\n",
    "        return \"down\" if v < 0 else \"up\"\n",
    "\n",
    "    # tie â†’ horizontal wins (gaze is steadier in horizontal axis)\n",
    "    return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "df[\"label\"] = df.apply(create_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1538ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    '''Load 2D images and their corresponding labels from a DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'path' and 'label' columns\n",
    "    \n",
    "    Returns:\n",
    "    images (np.ndarray): A numpy array of shape (N, H, W, 3)\n",
    "    labels (np.ndarray): A numpy array of shape (N)\n",
    "    '''\n",
    "    \n",
    "    # initialize lists to store data\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # iterate over DataFrame rows\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = row['path']\n",
    "        label = row['label']\n",
    "        \n",
    "        # load image\n",
    "        img = load_img(img_path)\n",
    "        # convert to array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # store data\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccffcfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # lol no, crashes the kernel\n",
    "# images, labels = load_data(df)\n",
    "# print(f\"Image shape: {images.shape}\")  # (N, 3456, 5184, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# Define your augmentation strategy\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "AUGMENTED_ROOT = Path(\"~/Documents/00_210/data/columbia_gaze_dataset_augmented\").expanduser()\n",
    "AUGMENTED_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def augment_and_save(df, num_augmentations_per_image=5, target_size=(512, 512)):\n",
    "    '''\n",
    "    Augment images and save them, preserving subject folder structure\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with image metadata including 'path', 'subject', etc.\n",
    "    num_augmentations_per_image (int): How many augmented versions to create per original\n",
    "    target_size (tuple): Size to resize images to (or None for original size)\n",
    "    \n",
    "    Returns:\n",
    "    augmented_df (pd.DataFrame): New DataFrame with augmented image info\n",
    "    '''\n",
    "    \n",
    "    augmented_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting images\"):\n",
    "        # Load original image\n",
    "        if target_size:\n",
    "            img = load_img(row['path'], target_size=target_size)\n",
    "        else:\n",
    "            img = load_img(row['path'])\n",
    "        \n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # shape: (1, H, W, 3)\n",
    "        \n",
    "        # Create subject directory in augmented dataset\n",
    "        subject_dir = AUGMENTED_ROOT / row['subject']\n",
    "        subject_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save original image first (optional, but maintains all originals)\n",
    "        original_filename = f\"{row['filename'].replace('.jpg', '')}_original.jpg\"\n",
    "        original_path = subject_dir / original_filename\n",
    "        array_to_img(img_array[0]).save(original_path)\n",
    "        \n",
    "        # Add original to augmented dataset\n",
    "        augmented_rows.append({\n",
    "            **row.to_dict(),  # keep all original metadata\n",
    "            'path': str(original_path),\n",
    "            'filename': original_filename,\n",
    "            'augmentation_type': 'original',\n",
    "            'augmentation_index': 0\n",
    "        })\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        aug_iter = augmentor.flow(img_array, batch_size=1)\n",
    "        \n",
    "        for aug_idx in range(num_augmentations_per_image):\n",
    "            augmented_img = next(aug_iter)[0]  # get one augmented image\n",
    "            \n",
    "            # Create filename that preserves original info\n",
    "            aug_filename = f\"{row['filename'].replace('.jpg', '')}_aug{aug_idx+1}.jpg\"\n",
    "            aug_path = subject_dir / aug_filename\n",
    "            \n",
    "            # Save augmented image\n",
    "            array_to_img(augmented_img).save(aug_path)\n",
    "            \n",
    "            # Add to metadata\n",
    "            augmented_rows.append({\n",
    "                **row.to_dict(),  # keep all original metadata (subject, gaze angles, etc.)\n",
    "                'path': str(aug_path),\n",
    "                'filename': aug_filename,\n",
    "                'augmentation_type': 'augmented',\n",
    "                'augmentation_index': aug_idx + 1\n",
    "            })\n",
    "    \n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    return augmented_df\n",
    "\n",
    "# Run augmentation\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "augmented_df = augment_and_save(df, num_augmentations_per_image=5, target_size=(512, 512))\n",
    "\n",
    "print(f\"\\nAugmented dataset size: {len(augmented_df)}\")\n",
    "print(f\"Images per original: {len(augmented_df) / len(df)}\")\n",
    "\n",
    "# Save the augmented metadata\n",
    "augmented_df.to_csv(AUGMENTED_ROOT / \"metadata.csv\", index=False)\n",
    "print(f\"\\nMetadata saved to: {AUGMENTED_ROOT / 'metadata.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e81753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentation strategy \n",
    "# Geometric augmentations\n",
    "rotation_range=15,  # rotate images randomly up to 15 degrees\n",
    "width_shift_range=0.15,  # shift horizontally by 15%\n",
    "height_shift_range=0.15,  # shift vertically by 15%\n",
    "shear_range=0.1,  # shear transformation\n",
    "zoom_range=0.15,  # zoom in/out randomly\n",
    "horizontal_flip=True,  # flip images horizontally (useful for gaze!)\n",
    "\n",
    "# Photometric augmentations (for lighting variations)\n",
    "brightness_range=[0.7, 1.3],  # darken or brighten\n",
    "\n",
    "fill_mode='nearest',  # how to fill in newly created pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c816a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class AugmentedDataGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size=32, target_size=(512, 512), augment=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(df))\n",
    "        \n",
    "        # Label encoding\n",
    "        self.label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "        self.num_classes = len(self.label_map)\n",
    "        \n",
    "        # Advanced augmentations for in-the-wild scenarios\n",
    "        self.transform = A.Compose([\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.3),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.RandomGamma(p=0.3),\n",
    "            A.CLAHE(p=0.2),  # better for varying lighting\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),  # simulate occlusions\n",
    "        ]) if augment else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            # Load image\n",
    "            img = cv2.imread(row['path'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, self.target_size)\n",
    "            \n",
    "            # Apply augmentation\n",
    "            if self.transform:\n",
    "                img = self.transform(image=img)['image']\n",
    "            \n",
    "            # Normalize\n",
    "            img = img / 255.0\n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(self.label_map[row['label']])\n",
    "        \n",
    "        return np.array(images), tf.keras.utils.to_categorical(labels, self.num_classes)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# Usage\n",
    "train_gen = AugmentedDataGenerator(df.iloc[:int(0.8*len(df))], augment=True)\n",
    "val_gen = AugmentedDataGenerator(df.iloc[int(0.8*len(df)):], augment=False)\n",
    "\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

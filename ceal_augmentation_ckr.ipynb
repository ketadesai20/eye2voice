{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7280b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy[version='<2']\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2026.01.04         |  py311hca03da5_0         149 KB\n",
      "    conda-24.11.3              |  py311hca03da5_0         1.2 MB\n",
      "    libopenblas-0.3.30         |       hf2bb037_2         4.1 MB\n",
      "    numpy-1.26.4               |  py311h901140f_1          14 KB\n",
      "    numpy-base-1.26.4          |  py311hae06d03_1         6.9 MB\n",
      "    openssl-3.0.19             |       ha0b305a_0         3.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        15.5 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2024.3.11-hca03da5_0 --> 2025.12.2-hca03da5_0 \n",
      "  certifi                          2024.6.2-py311hca03da5_0 --> 2026.01.04-py311hca03da5_0 \n",
      "  conda                              24.5.0-py311hca03da5_0 --> 24.11.3-py311hca03da5_0 \n",
      "  libopenblas                             0.3.21-h269037a_0 --> 0.3.30-hf2bb037_2 \n",
      "  numpy                              1.26.4-py311he598dae_0 --> 1.26.4-py311h901140f_1 \n",
      "  numpy-base                         1.26.4-py311hfbfe69c_0 --> 1.26.4-py311hae06d03_1 \n",
      "  openssl                                 3.0.14-h80987f9_0 --> 3.0.19-ha0b305a_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | "
     ]
    }
   ],
   "source": [
    "!conda activate base\n",
    "!conda install \"numpy<2\"\n",
    "!conda install -c conda-forge --yes pyarrow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fb642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/89/572hqr1x26j5sf69pfl_2fd80000gn/T/ipykernel_18290/1409394735.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/89/572hqr1x26j5sf69pfl_2fd80000gn/T/ipykernel_18290/1409394735.py\", line 3, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# imports\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     ArrowDtype,\n\u001b[1;32m     52\u001b[0m     Int8Dtype,\n\u001b[1;32m     53\u001b[0m     Int16Dtype,\n\u001b[1;32m     54\u001b[0m     Int32Dtype,\n\u001b[1;32m     55\u001b[0m     Int64Dtype,\n\u001b[1;32m     56\u001b[0m     UInt8Dtype,\n\u001b[1;32m     57\u001b[0m     UInt16Dtype,\n\u001b[1;32m     58\u001b[0m     UInt32Dtype,\n\u001b[1;32m     59\u001b[0m     UInt64Dtype,\n\u001b[1;32m     60\u001b[0m     Float32Dtype,\n\u001b[1;32m     61\u001b[0m     Float64Dtype,\n\u001b[1;32m     62\u001b[0m     CategoricalDtype,\n\u001b[1;32m     63\u001b[0m     PeriodDtype,\n\u001b[1;32m     64\u001b[0m     IntervalDtype,\n\u001b[1;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     66\u001b[0m     StringDtype,\n\u001b[1;32m     67\u001b[0m     BooleanDtype,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     NA,\n\u001b[1;32m     70\u001b[0m     isna,\n\u001b[1;32m     71\u001b[0m     isnull,\n\u001b[1;32m     72\u001b[0m     notna,\n\u001b[1;32m     73\u001b[0m     notnull,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     Index,\n\u001b[1;32m     76\u001b[0m     CategoricalIndex,\n\u001b[1;32m     77\u001b[0m     RangeIndex,\n\u001b[1;32m     78\u001b[0m     MultiIndex,\n\u001b[1;32m     79\u001b[0m     IntervalIndex,\n\u001b[1;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     81\u001b[0m     DatetimeIndex,\n\u001b[1;32m     82\u001b[0m     PeriodIndex,\n\u001b[1;32m     83\u001b[0m     IndexSlice,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     NaT,\n\u001b[1;32m     86\u001b[0m     Period,\n\u001b[1;32m     87\u001b[0m     period_range,\n\u001b[1;32m     88\u001b[0m     Timedelta,\n\u001b[1;32m     89\u001b[0m     timedelta_range,\n\u001b[1;32m     90\u001b[0m     Timestamp,\n\u001b[1;32m     91\u001b[0m     date_range,\n\u001b[1;32m     92\u001b[0m     bdate_range,\n\u001b[1;32m     93\u001b[0m     Interval,\n\u001b[1;32m     94\u001b[0m     interval_range,\n\u001b[1;32m     95\u001b[0m     DateOffset,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     to_numeric,\n\u001b[1;32m     98\u001b[0m     to_datetime,\n\u001b[1;32m     99\u001b[0m     to_timedelta,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     Flags,\n\u001b[1;32m    102\u001b[0m     Grouper,\n\u001b[1;32m    103\u001b[0m     factorize,\n\u001b[1;32m    104\u001b[0m     unique,\n\u001b[1;32m    105\u001b[0m     value_counts,\n\u001b[1;32m    106\u001b[0m     NamedAgg,\n\u001b[1;32m    107\u001b[0m     array,\n\u001b[1;32m    108\u001b[0m     Categorical,\n\u001b[1;32m    109\u001b[0m     set_eng_float_format,\n\u001b[1;32m    110\u001b[0m     Series,\n\u001b[1;32m    111\u001b[0m     DataFrame,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/__init__.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import albumentations as A\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tqdm import tqdm  # for progress bar\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994471b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent my poor mac from overheating\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb632388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image metadata\n",
    "DATA_ROOT = Path(\"~/Documents/00_210/data/columbia_gaze_dataset\").expanduser()\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Regex for filename parsing\n",
    "pattern = re.compile(\n",
    "    r\"(?P<subject>\\d+)_\"\n",
    "    r\"(?P<distance>\\d+)m_\"\n",
    "    r\"(?P<head_pose>-?\\d+)P_\"\n",
    "    r\"(?P<gaze_v>-?\\d+)V_\"\n",
    "    r\"(?P<gaze_h>-?\\d+)H\\.jpg\"\n",
    ")\n",
    "\n",
    "for subject_dir in DATA_ROOT.iterdir():\n",
    "    if not subject_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for img_path in subject_dir.glob(\"*.jpg\"):\n",
    "        match = pattern.match(img_path.name)\n",
    "        if not match:\n",
    "            continue  # skip unexpected filenames\n",
    "\n",
    "        meta = match.groupdict()\n",
    "\n",
    "        rows.append({\n",
    "            \"path\": str(img_path),\n",
    "            \"filename\": img_path.name,\n",
    "            \"subject\": meta[\"subject\"],\n",
    "            \"distance_m\": int(meta[\"distance\"]),\n",
    "            \"head_pose_deg\": int(meta[\"head_pose\"]),\n",
    "            \"gaze_vertical_deg\": int(meta[\"gaze_v\"]),\n",
    "            \"gaze_horizontal_deg\": int(meta[\"gaze_h\"]),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525d462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels based on degrees\n",
    "def create_labels(row):\n",
    "    '''\n",
    "    converts per-image gaze metadata into an intent-level\n",
    "    classification\n",
    "    '''\n",
    "    h = row[\"gaze_horizontal_deg\"]\n",
    "    v = row[\"gaze_vertical_deg\"]\n",
    "\n",
    "    # straight\n",
    "    if v==0 and h==0: \n",
    "        return \"straight\"\n",
    "    \n",
    "    # horizontal dominates\n",
    "    if abs(h) > abs(v):\n",
    "        return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "    # vertical dominates\n",
    "    if abs(v) > abs(h):\n",
    "        return \"down\" if v < 0 else \"up\"\n",
    "\n",
    "    # tie â†’ horizontal wins (gaze is steadier in horizontal axis)\n",
    "    return \"left\" if h < 0 else \"right\"\n",
    "\n",
    "df[\"label\"] = df.apply(create_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1538ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    '''Load 2D images and their corresponding labels from a DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'path' and 'label' columns\n",
    "    \n",
    "    Returns:\n",
    "    images (np.ndarray): A numpy array of shape (N, H, W, 3)\n",
    "    labels (np.ndarray): A numpy array of shape (N)\n",
    "    '''\n",
    "    \n",
    "    # initialize lists to store data\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # iterate over DataFrame rows\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = row['path']\n",
    "        label = row['label']\n",
    "        \n",
    "        # load image\n",
    "        img = load_img(img_path)\n",
    "        # convert to array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # store data\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccffcfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # lol no, crashes the kernel\n",
    "# images, labels = load_data(df)\n",
    "# print(f\"Image shape: {images.shape}\")  # (N, 3456, 5184, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# Define your augmentation strategy\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "AUGMENTED_ROOT = Path(\"~/Documents/00_210/data/columbia_gaze_dataset_augmented\").expanduser()\n",
    "AUGMENTED_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def augment_and_save(df, num_augmentations_per_image=5, target_size=(512, 512)):\n",
    "    '''\n",
    "    Augment images and save them, preserving subject folder structure\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with image metadata including 'path', 'subject', etc.\n",
    "    num_augmentations_per_image (int): How many augmented versions to create per original\n",
    "    target_size (tuple): Size to resize images to (or None for original size)\n",
    "    \n",
    "    Returns:\n",
    "    augmented_df (pd.DataFrame): New DataFrame with augmented image info\n",
    "    '''\n",
    "    \n",
    "    augmented_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting images\"):\n",
    "        # Load original image\n",
    "        if target_size:\n",
    "            img = load_img(row['path'], target_size=target_size)\n",
    "        else:\n",
    "            img = load_img(row['path'])\n",
    "        \n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # shape: (1, H, W, 3)\n",
    "        \n",
    "        # Create subject directory in augmented dataset\n",
    "        subject_dir = AUGMENTED_ROOT / row['subject']\n",
    "        subject_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save original image first (optional, but maintains all originals)\n",
    "        original_filename = f\"{row['filename'].replace('.jpg', '')}_original.jpg\"\n",
    "        original_path = subject_dir / original_filename\n",
    "        array_to_img(img_array[0]).save(original_path)\n",
    "        \n",
    "        # Add original to augmented dataset\n",
    "        augmented_rows.append({\n",
    "            **row.to_dict(),  # keep all original metadata\n",
    "            'path': str(original_path),\n",
    "            'filename': original_filename,\n",
    "            'augmentation_type': 'original',\n",
    "            'augmentation_index': 0\n",
    "        })\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        aug_iter = augmentor.flow(img_array, batch_size=1)\n",
    "        \n",
    "        for aug_idx in range(num_augmentations_per_image):\n",
    "            augmented_img = next(aug_iter)[0]  # get one augmented image\n",
    "            \n",
    "            # Create filename that preserves original info\n",
    "            aug_filename = f\"{row['filename'].replace('.jpg', '')}_aug{aug_idx+1}.jpg\"\n",
    "            aug_path = subject_dir / aug_filename\n",
    "            \n",
    "            # Save augmented image\n",
    "            array_to_img(augmented_img).save(aug_path)\n",
    "            \n",
    "            # Add to metadata\n",
    "            augmented_rows.append({\n",
    "                **row.to_dict(),  # keep all original metadata (subject, gaze angles, etc.)\n",
    "                'path': str(aug_path),\n",
    "                'filename': aug_filename,\n",
    "                'augmentation_type': 'augmented',\n",
    "                'augmentation_index': aug_idx + 1\n",
    "            })\n",
    "    \n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    return augmented_df\n",
    "\n",
    "# Run augmentation\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "augmented_df = augment_and_save(df, num_augmentations_per_image=5, target_size=(512, 512))\n",
    "\n",
    "print(f\"\\nAugmented dataset size: {len(augmented_df)}\")\n",
    "print(f\"Images per original: {len(augmented_df) / len(df)}\")\n",
    "\n",
    "# Save the augmented metadata\n",
    "augmented_df.to_csv(AUGMENTED_ROOT / \"metadata.csv\", index=False)\n",
    "print(f\"\\nMetadata saved to: {AUGMENTED_ROOT / 'metadata.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e81753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentation strategy \n",
    "# Geometric augmentations\n",
    "rotation_range=15,  # rotate images randomly up to 15 degrees\n",
    "width_shift_range=0.15,  # shift horizontally by 15%\n",
    "height_shift_range=0.15,  # shift vertically by 15%\n",
    "shear_range=0.1,  # shear transformation\n",
    "zoom_range=0.15,  # zoom in/out randomly\n",
    "horizontal_flip=True,  # flip images horizontally (useful for gaze!)\n",
    "\n",
    "# Photometric augmentations (for lighting variations)\n",
    "brightness_range=[0.7, 1.3],  # darken or brighten\n",
    "\n",
    "fill_mode='nearest',  # how to fill in newly created pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c816a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size=32, target_size=(512, 512), augment=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(df))\n",
    "        \n",
    "        # Label encoding\n",
    "        self.label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "        self.num_classes = len(self.label_map)\n",
    "        \n",
    "        # Advanced augmentations for in-the-wild scenarios\n",
    "        self.transform = A.Compose([\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.3),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.RandomGamma(p=0.3),\n",
    "            A.CLAHE(p=0.2),  # better for varying lighting\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),  # simulate occlusions\n",
    "        ]) if augment else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            # Load image\n",
    "            img = cv2.imread(row['path'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, self.target_size)\n",
    "            \n",
    "            # Apply augmentation\n",
    "            if self.transform:\n",
    "                img = self.transform(image=img)['image']\n",
    "            \n",
    "            # Normalize\n",
    "            img = img / 255.0\n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(self.label_map[row['label']])\n",
    "        \n",
    "        return np.array(images), tf.keras.utils.to_categorical(labels, self.num_classes)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# Usage\n",
    "train_gen = AugmentedDataGenerator(df.iloc[:int(0.8*len(df))], augment=True)\n",
    "val_gen = AugmentedDataGenerator(df.iloc[int(0.8*len(df)):], augment=False)\n",
    "\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
